Our new idea:
- create an adversarial attack that gives the impression of multiple objects rather than reduce the amount of objects classified as seen by more recent adversarial attacks
- WHAT WE SAY: We will work on making a physical adversarial patch robust against physical alterations such as wrinkles, bending, curvature
    - motivation: it allows for more adaptable usage of adversarial attacks against object detection systems
    - a side thought for this proposal would be to fool object detection systems into multiple classifications of an object vs the traditional attack that reduces the accuracy of the model 
    - our particular target is object detection within traffic video surveillance 
        - our side thought was to explore the possibility of tricking the model into additional misclassifications

NOtes for repo setup: you have to manually donwload inception 3 weights from tf. repo, create wenv 3with python=3.5 and create folder for graphs.

https://slavainder.github.io/209AS-winter-2020/ 
